# Where you’re strong (good prototype bones)

* **Kernel exists and runs end-to-end**: `PTKKernel.simulate_emission` propagates +/− packets, performs partial cancellation by frequency/phase, and emits multiple particles/fields with detections. Tests assert non-trivial output. (see `pt-sim/pt_sim/ptk_kernel.py` and `tests/test_kernel_emission.py`). 
* **Wiring to “detection” works**: bridge converts kernel outputs into ECAL-like images; tests verify non-zero images (`pt-sim/pt_sim/detector/bridge.py`, `tests/test_detector_bridge.py`, `tests/test_kernel_wiring.py`). 
* **Visualization**: static and animated overlays for +/− flows (`gen__kernel_viz.py`, `gen__kernel_anime.py`, `tools/viz_overlay.py`). 
* **Data formats**: a stable PTK v1 kernel + layout generator and a schema validator exist (`generate_ptk_artifacts.py`, `ptk_pydantic_validator.py`). 
* **Physics sandboxes**: toy EM shower models, Lorentz motion, and QCD-like flux tube demos show healthy curiosity and scaffolding for future realism (`pt-sim/pt_sim/physics/*`, `pt-sim/pt_sim/demo_forces.py`). 

# Red flags blocking “CERN-grade”

1. ## Scientific rigor / first principles

   * **Heuristic dynamics**: energy “gains,” split_decay, and cancellation efficiency are ad-hoc; there’s no **conservation accounting** proving that particles+fields+residuals equal inputs at every step. (see `simulate_emission` internals). 
   * **No action/symmetry basis**: there’s no action, symmetry group, or invariants stated (e.g., level-matching analogue for ± lobes), so results are not tied to a falsifiable theoretical structure.

2. ## Reproducibility & provenance

   * **Side effects on import**: `ptk_kernel.py` executes a simulation and writes `ptk_emission_result.json` at module import time (not guarded by `if __name__ == "__main__":`). This will fire during package import and in tests—non-deterministic behavior in CI. 
   * **No seed control** in kernel or detector bridge; studies can’t be reproduced bit-exactly.

3. ## Detector/geometry realism

   * **Detector bridge is a toy**: node→grid mapping is arbitrary and fields are uniform washes; no geometry, calibration, or digitization consistent with real detectors yet (`pt-sim/pt_sim/detector/bridge.py`). 

4. ## Validation & metrics

   * **No physics-style validation**: there are no energy closure tests for the kernel (you do have closure tests for shower models), no stability studies, and no benchmark datasets / golden outputs across parameter sweeps. (Only smoke tests ensure “non-zero output”). 

5. ## Software engineering for scale

   * **No HPC path yet**: Rust “fastcore” loader is stubbed (`pt-sim/pt_sim/fastcore.py`), but the kernel itself runs pure Python; no GPU vectorization or Rust core for large sweeps. 
   * **Schema governance**: PTK v1 exists but there’s no JSON-Schema, migrations, or compatibility tests across versions baked into CI beyond the Pydantic script. 
   * **Docs & interfaces**: CLI exists for emission (`tools/run_emission.py`) but there’s no versioned API contract, no docstrings/specs for inputs/outputs, and no experiment logging standard. 

# Immediate fixes (surgical, copy-paste level)

* **Kill import side-effects** in `pt-sim/pt_sim/ptk_kernel.py`: wrap the bottom simulation block with:

  ```python
  if __name__ == "__main__":
      # demo run here
  ```

  (Prevents unintended I/O on import.) 
* **Energy accounting**: inside `simulate_emission`, maintain an `energy_ledger` with:

  * input sum
  * per-step: energy on edges, energy canceled, energy → fields, energy → particles, energy lost to split_decay
  * assert |in − out|/in < ε at every step; add a unit test that sweeps configs and enforces near-closure.
* **Determinism**: add a `rng_seed` to `EmissionConfig`; use it wherever stochasticity may be introduced now or later (even if currently deterministic).
* **JSON-Schema & versioning**: emit `ptk.v1.schema.json`; validate it in CI alongside Pydantic, and add a “version bump required” test when fields change.
* **Document the I/O** of `tools/run_emission.py` and `pt_sim.detector.run_from_kernel`: specify JSON input schema for sounds/cfg and NPZ output contents.

# Short-term upgrades (2–4 weeks)

1. **Physics hygiene**

   * Implement **global and per-edge energy conservation**: `gain` should model attenuation; conservation must hold once you count (particles + fields + remaining packet energy). Add tests that fail if energy drift > 1–2%.
   * Add **left/right (±) level-matching** constraint per path before emission triggers (analogue to string theory), and track symmetry violations as debug counters.

2. **Validation harness**

   * Create **grid sweeps** over frequency, phase, coherence; store outputs in a versioned dataset; compute **yield surfaces** (particles vs fields) and **stability maps**. Add baseline plots to `out/benchmarks/`.
   * Golden-file tests: for a fixed seed + config, pin exact JSON outputs (or hashes) to detect regressions.

3. **Detector realism**

   * Replace `_node_to_xy` with a declarative **geometry mapping** (YAML/JSON) and plug a more realistic field pattern (edge-localized ribbons, not uniform wash). Add digitization noise similar to `physics/accurate.py` pathways. 

4. **Performance path**

   * Port the inner loop of `simulate_emission` to **Rust** with PyO3 (mirror structs you already have) and enable parallel packet stepping; keep Python as orchestrator. (You already have a Rust pattern in `fastcore.py`.) 

# Medium-term (1–3 months)

* **Formal model**: write a minimal **action** or rule system that the kernel is an integrator for (define invariants/symmetries). Publish a tech note that states assumptions and derived consequences.
* **Uncertainty & calibration**: add error bars/bootstraps on yields; define calibration knobs and store them distinctly from physical “constants.”
* **Experiment management**: standardize an experiment log (e.g., JSONL or MLFlow-like) capturing kernel version, PTK hash, layout hash, config, RNG seed, outputs, and plots.
* **CI hardening**: add long-running “nightly” sweeps; enforce schema/version bumps on incompatible changes; add a docs job to publish API & theory notes.

# What “CERN-grade” will require (beyond code)

* **Theory ↔ code traceability**: written theoretical framework with peer review.
* **Data governance**: curated datasets, access policies, and provenance.
* **Reproducible pipelines at scale**: containerized runs, cluster or GPU scheduling, artifact registries.
* **Independent validation**: cross-checks by external collaborators; blinded studies; challenge datasets.
* **Documentation**: user/developer guides, API specs, and a public benchmark suite.

# Verdict

* **Today**: strong research prototype with functioning kernels, visualization, tests, and IO stubs.
* **Not yet CERN-grade**: needs conservation laws, formalization, deterministic provenance, realistic detector modeling, performance, and rigorous validation.

